{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7c5c60-cab8-46c8-88bf-9490b22604ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings generated: 1\n",
      "What is Task 2?\n",
      "File: sithafalpdf.pdf, Chunk: Task 2: Chat with Website Using RAG Pipeline Overview The goal is to implement a Retrieval-Augmented Generation (RAG) pipeline that allows users to interact with structured and unstructured data extracted from websites. The system will crawl, scrape, and store website content, convert it into embeddings, and store it in a vector database. Users can query the system for information and receive accurate, context-rich responses generated by a selected LLM. Functional Requirements 1. Data Ingestion • Input: URLs or list of websites to crawl/scrape. • Process: o Crawl and scrape content from target websites. o Extract key data ﬁelds, metadata, and textual content. o Segment content into chunks for better granularity. o Convert chunks into vector embeddings using a pre-trained embedding model. o Store embeddings in a vector database with associated metadata for eFicient retrieval. 2. Query Handling • Input: User's natural language question. • Process: o Convert the user's query into vector embeddings using the same embedding model. o Perform a similarity search in the vector database to retrieve the most relevant chunks. o Pass the retrieved chunks to the LLM along with a prompt or agentic context to generate a detailed response. o 3. Response Generation • Input: Relevant information retrieved from the vector database and the user query. • Process: o Use the LLM with retrieval-augmented prompts to produce responses with exact values and context. o Ensure factuality by incorporating retrieved data directly into the response. Example website links : https://www.uchicago.edu/ https://www.washington.edu/ https://www.stanford.edu/ https://und.edu/, Score: 0.8207303285598755\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Path to a single PDF file\n",
    "pdf_path = r\"C:\\Users\\LAKSHMI_SRAVANTHI\\Downloads\\sithafalpdf.pdf\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.isfile(pdf_path):\n",
    "    raise FileNotFoundError(f\"The file '{pdf_path}' does not exist. Please provide a valid PDF file.\")\n",
    "\n",
    "# Load Sentence-BERT model for embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to extract text from specific pages of a PDF\n",
    "def extract_text_from_pdf(pdf_path, pages=[2, 6]):\n",
    "    text_chunks = []\n",
    "    reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # Check if the pages list is within bounds of the PDF\n",
    "    total_pages = len(reader.pages)\n",
    "    for page_num in pages:\n",
    "        if page_num <= total_pages:\n",
    "            text = reader.pages[page_num - 1].extract_text()  # Page numbers are 1-based\n",
    "            if text:\n",
    "                text_chunks.append(text)\n",
    "    return text_chunks\n",
    "\n",
    "# Function to chunk text into smaller parts for processing\n",
    "def chunk_text(text, max_chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(current_chunk) >= max_chunk_size:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# Function to store embeddings in a NearestNeighbors model\n",
    "def store_embeddings_in_knn(embeddings, metadata):\n",
    "    knn = NearestNeighbors(n_neighbors=min(5, len(embeddings)), algorithm='auto', metric='cosine')\n",
    "    knn.fit(embeddings)\n",
    "    return knn, metadata\n",
    "\n",
    "# Process the single PDF file and generate embeddings\n",
    "all_embeddings = []\n",
    "metadata = []\n",
    "\n",
    "# Extract text from specific pages (e.g., 2 and 6)\n",
    "text_chunks = extract_text_from_pdf(pdf_path)\n",
    "for text in text_chunks:\n",
    "    chunks = chunk_text(text)\n",
    "    embeddings = model.encode(chunks)  # Use Sentence-BERT for embeddings\n",
    "    all_embeddings.extend(embeddings)\n",
    "    metadata.extend([(os.path.basename(pdf_path), chunk) for chunk in chunks])\n",
    "\n",
    "# Check if embeddings are generated correctly\n",
    "print(f\"Total embeddings generated: {len(all_embeddings)}\")\n",
    "\n",
    "if len(all_embeddings) == 0:\n",
    "    raise ValueError(\"No embeddings were generated. Please check the PDF content and extraction process.\")\n",
    "\n",
    "# Convert embeddings to numpy array\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "# Store embeddings using NearestNeighbors\n",
    "knn, metadata = store_embeddings_in_knn(all_embeddings, metadata)\n",
    "\n",
    "# Query Handling function\n",
    "def query_knn(query, knn, metadata, top_k=5):\n",
    "    query_embedding = model.encode([query]).reshape(1, -1)\n",
    "    \n",
    "    # Dynamically adjust n_neighbors if there are fewer than 5 embeddings\n",
    "    n_neighbors = min(top_k, len(all_embeddings))\n",
    "    \n",
    "    distances, indices = knn.kneighbors(query_embedding, n_neighbors=n_neighbors)\n",
    "    results = [(metadata[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "    return results\n",
    "\n",
    "# Example Query: Retrieve information\n",
    "query = \"What is Task 2?\"\n",
    "results = query_knn(query, knn, metadata)\n",
    "print(query)\n",
    "for (file_chunk, score) in results:\n",
    "    print(f\"File: {file_chunk[0]}, Chunk: {file_chunk[1]}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda61b98-d3c3-4de6-a595-9c9057586209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
